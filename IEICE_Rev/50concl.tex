\section{Conclusion}
In this paper, for an integer $k~(k\ge 2)$, we have shown the conditions on the number of constant symbols in $\Sigma$, summarized in Table \ref{table:results}, required for the classes $\RPatkei$ of all the set of $k$ regular pattern languages and $\NAVRPkei$ of all the set of $k$ non-adjacent variable regular patterns in $\NAVRP$ to have compactness with respect to containment.
This result leads to design an efficient learning algorithm for finite unions of languages of non-adjacent variable regular patterns in $\NAVRP$, based on the learning algorithm for $\RPatkei$ proposed by Arimura et al.~\cite{Arimura1994}.
\begin{table}
\caption{The conditions on the number $\sharp \Sigma$ of constant symbols in $\Sigma$ required for compactness with respect to containment.}\label{table:results}
\begin{center}
\begin{tabular}{c|c|c}
  Class & $k=2$ & $k\ge 3$\\
  \hline
  \raisebox{-5pt}{$\RPatkei$} & \raisebox{-5pt}{$\sharp \Sigma \ge 4$} & \raisebox{-5pt}{$\sharp \Sigma \ge 2k-1$} \\[10pt]
  \hline
  \raisebox{-5pt}{$\NAVRPkei$} & \multicolumn{2}{c}{\raisebox{-5pt}{$\sharp \Sigma \ge k+2$}}\\[10pt]
\end{tabular}
\end{center}
\vspace*{-10pt}
\end{table}

Extending the notion of strong compactness, as introduced by Arimura et al.~\cite{Arimura1996}, to finite unions of regular pattern languages with non-adjacent variables remains as a topic for future research.
Furthermore, based on the characteristic set for $\NAVRPkei$, we plan to propose a polynomial-time inductive inference algorithm that identifies finite unions of regular pattern languages with non-adjacent variables in the limit from positive examples.
%Moreover, we are actively working on accelerating a query learning algorithm capable of identifying, with a single positive example and a polynomial number of membership queries, target concepts represented as unions of regular pattern languages with non-adjacent variables.
%Uchida et al. \cite{Uchida2019} introduced a primitive formal ordered tree system (pFOTS) as a formal system defining labeled ordered tree languages and discussed exact Learning of Tree Languages with background pFOTS programs having only one predicate symbol via queries.
Ishinada et al. \cite{Ishinada2023} investigated a query learning model that employs high-precision Graph Convolution Networks (GCNs) as oracles for tree patterns.
Applying the findings of the present study to tree pattern languages, with the aim of enabling the extension of their work to finite unions of tree pattern languages, remains an important direction for future research.